{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import List\n",
    "\n",
    "from copy import copy\n",
    "from itertools import combinations, permutations\n",
    "import pickle\n",
    "from random import choice, random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a convex function\n",
    "def sort_loss(input: List[int]) -> float:\n",
    "    loss = 0\n",
    "    for i in range(len(input)):\n",
    "        for j in range(i, len(input)):\n",
    "            if input[i] > input[j]:\n",
    "                loss += 1\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_swaps_possible(input: List[int]) -> List[List[int]]:\n",
    "    res = []\n",
    "    for i in range(len(input)-1):\n",
    "        input_copy = copy(input)\n",
    "        input_copy[i], input_copy[i+1] = input_copy[i+1], input_copy[i]\n",
    "        res.append(input_copy)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_loss([1,5,4,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate simple data\n",
    "SOURCE = [x for x in range(7)]\n",
    "DATASET_SIZE = 10\n",
    "SEQ_LEN = 4\n",
    "\n",
    "DATA = []\n",
    "\n",
    "SAMPLES = list(permutations(SOURCE, SEQ_LEN))\n",
    "_picked = set()\n",
    "for _ in range(10):\n",
    "    v = choice(SAMPLES)\n",
    "    if v not in _picked:\n",
    "        _picked.add(v)\n",
    "\n",
    "    swap_chosen = None\n",
    "    for swap in get_swaps_possible(list(v)):\n",
    "        if swap_chosen is None:\n",
    "            swap_chosen = swap\n",
    "        if sort_loss(swap) < sort_loss(swap_chosen):\n",
    "            swap_chosen = swap\n",
    "    \n",
    "    DATA.append((list(v), swap_chosen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 2, 0, 3], [1, 0, 2, 3]),\n",
       " ([0, 5, 2, 3], [0, 2, 5, 3]),\n",
       " ([6, 3, 1, 4], [3, 6, 1, 4]),\n",
       " ([6, 1, 5, 3], [1, 6, 5, 3]),\n",
       " ([0, 3, 4, 5], [3, 0, 4, 5]),\n",
       " ([2, 1, 6, 3], [1, 2, 6, 3]),\n",
       " ([6, 1, 4, 2], [1, 6, 4, 2]),\n",
       " ([5, 0, 1, 6], [0, 5, 1, 6]),\n",
       " ([4, 6, 2, 3], [4, 2, 6, 3]),\n",
       " ([2, 1, 6, 0], [1, 2, 6, 0])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "\n",
      "([1, 2, 0, 3], [1, 0, 2, 3])\n",
      "------------------\n",
      "\n",
      "[2, 1, 0, 3] 3\n",
      "[1, 0, 2, 3] 1\n",
      "[1, 2, 3, 0] 3\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([0, 5, 2, 3], [0, 2, 5, 3])\n",
      "------------------\n",
      "\n",
      "[5, 0, 2, 3] 3\n",
      "[0, 2, 5, 3] 1\n",
      "[0, 5, 3, 2] 3\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([6, 3, 1, 4], [3, 6, 1, 4])\n",
      "------------------\n",
      "\n",
      "[3, 6, 1, 4] 3\n",
      "[6, 1, 3, 4] 3\n",
      "[6, 3, 4, 1] 5\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([6, 1, 5, 3], [1, 6, 5, 3])\n",
      "------------------\n",
      "\n",
      "[1, 6, 5, 3] 3\n",
      "[6, 5, 1, 3] 5\n",
      "[6, 1, 3, 5] 3\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([0, 3, 4, 5], [3, 0, 4, 5])\n",
      "------------------\n",
      "\n",
      "[3, 0, 4, 5] 1\n",
      "[0, 4, 3, 5] 1\n",
      "[0, 3, 5, 4] 1\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([2, 1, 6, 3], [1, 2, 6, 3])\n",
      "------------------\n",
      "\n",
      "[1, 2, 6, 3] 1\n",
      "[2, 6, 1, 3] 3\n",
      "[2, 1, 3, 6] 1\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([6, 1, 4, 2], [1, 6, 4, 2])\n",
      "------------------\n",
      "\n",
      "[1, 6, 4, 2] 3\n",
      "[6, 4, 1, 2] 5\n",
      "[6, 1, 2, 4] 3\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([5, 0, 1, 6], [0, 5, 1, 6])\n",
      "------------------\n",
      "\n",
      "[0, 5, 1, 6] 1\n",
      "[5, 1, 0, 6] 3\n",
      "[5, 0, 6, 1] 3\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([4, 6, 2, 3], [4, 2, 6, 3])\n",
      "------------------\n",
      "\n",
      "[6, 4, 2, 3] 5\n",
      "[4, 2, 6, 3] 3\n",
      "[4, 6, 3, 2] 5\n",
      "-------------------\n",
      "\n",
      "------------------\n",
      "\n",
      "([2, 1, 6, 0], [1, 2, 6, 0])\n",
      "------------------\n",
      "\n",
      "[1, 2, 6, 0] 3\n",
      "[2, 6, 1, 0] 5\n",
      "[2, 1, 0, 6] 3\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "for i, row in enumerate(DATA):\n",
    "    if i > 9:\n",
    "        break\n",
    "    print('------------------\\n')\n",
    "    print(row)\n",
    "    print('------------------\\n')\n",
    "    for v in get_swaps_possible(row[0]):\n",
    "        print(v, sort_loss(v))\n",
    "    print('-------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATE = 0.8\n",
    "train_data = []\n",
    "test_data = []\n",
    "for row in DATA:\n",
    "    if random() < SPLIT_RATE:\n",
    "        train_data.append(row)\n",
    "    else:\n",
    "        test_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open('../data/test.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([2, 1, 6, 0], [1, 2, 6, 0])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('../data/test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a simple sorter NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SorterNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SorterNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_data = torch.tensor([x[0] for x in train_data], dtype=torch.float32)\n",
    "output_train_data = torch.tensor([x[1] for x in train_data], dtype=torch.float32)\n",
    "\n",
    "input_test_data = torch.tensor([x[0] for x in test_data], dtype=torch.float32)\n",
    "output_test_data = torch.tensor([x[1] for x in test_data], dtype=torch.float32)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], dtype=torch.float32)\n",
    "output_data = torch.tensor([[10, 20, 30], [40, 50, 60], [70, 80, 90], [100, 110, 120]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = input_data.shape[1]\n",
    "output_size = output_data.shape[1]\n",
    "hidden_size = 64\n",
    "model = SorterNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/5000], Loss: 2582.2021\n",
      "Epoch [200/5000], Loss: 325.3589\n",
      "Epoch [300/5000], Loss: 21.1943\n",
      "Epoch [400/5000], Loss: 15.2081\n",
      "Epoch [500/5000], Loss: 15.0118\n",
      "Epoch [600/5000], Loss: 14.8628\n",
      "Epoch [700/5000], Loss: 14.7003\n",
      "Epoch [800/5000], Loss: 14.5249\n",
      "Epoch [900/5000], Loss: 14.3375\n",
      "Epoch [1000/5000], Loss: 14.1387\n",
      "Epoch [1100/5000], Loss: 13.9292\n",
      "Epoch [1200/5000], Loss: 13.7093\n",
      "Epoch [1300/5000], Loss: 13.4795\n",
      "Epoch [1400/5000], Loss: 13.2398\n",
      "Epoch [1500/5000], Loss: 12.9903\n",
      "Epoch [1600/5000], Loss: 12.7311\n",
      "Epoch [1700/5000], Loss: 12.4618\n",
      "Epoch [1800/5000], Loss: 12.1821\n",
      "Epoch [1900/5000], Loss: 11.8914\n",
      "Epoch [2000/5000], Loss: 11.5892\n",
      "Epoch [2100/5000], Loss: 11.2744\n",
      "Epoch [2200/5000], Loss: 10.9460\n",
      "Epoch [2300/5000], Loss: 10.6028\n",
      "Epoch [2400/5000], Loss: 10.2435\n",
      "Epoch [2500/5000], Loss: 9.8666\n",
      "Epoch [2600/5000], Loss: 9.4705\n",
      "Epoch [2700/5000], Loss: 9.0538\n",
      "Epoch [2800/5000], Loss: 8.6149\n",
      "Epoch [2900/5000], Loss: 8.1528\n",
      "Epoch [3000/5000], Loss: 7.6667\n",
      "Epoch [3100/5000], Loss: 7.1566\n",
      "Epoch [3200/5000], Loss: 6.6234\n",
      "Epoch [3300/5000], Loss: 6.0692\n",
      "Epoch [3400/5000], Loss: 5.4978\n",
      "Epoch [3500/5000], Loss: 4.9147\n",
      "Epoch [3600/5000], Loss: 4.3275\n",
      "Epoch [3700/5000], Loss: 3.7454\n",
      "Epoch [3800/5000], Loss: 3.1795\n",
      "Epoch [3900/5000], Loss: 2.6414\n",
      "Epoch [4000/5000], Loss: 2.1429\n",
      "Epoch [4100/5000], Loss: 1.6940\n",
      "Epoch [4200/5000], Loss: 1.3026\n",
      "Epoch [4300/5000], Loss: 0.9727\n",
      "Epoch [4400/5000], Loss: 0.7048\n",
      "Epoch [4500/5000], Loss: 0.4952\n",
      "Epoch [4600/5000], Loss: 0.3376\n",
      "Epoch [4700/5000], Loss: 0.2236\n",
      "Epoch [4800/5000], Loss: 0.1441\n",
      "Epoch [4900/5000], Loss: 0.0907\n",
      "Epoch [5000/5000], Loss: 0.0560\n",
      "Predicted Output: [[159.02127 201.54381 238.22298]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(input_data)\n",
    "    loss = criterion(outputs, output_data)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.tensor([[10, 20, 30]], dtype=torch.float32)\n",
    "predicted_output = model(test_input)\n",
    "print(\"Predicted Output:\", predicted_output.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
